{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/carlopizzuto/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "m, n = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "data_dev = data[:1000].T\n",
    "Y_dev = data_dev[0]\n",
    "X_dev = data_dev[1:n]\n",
    "X_dev = X_dev / 255.\n",
    "\n",
    "data_train = data[1000:m].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n]\n",
    "X_train = X_train / 255.\n",
    "_, m_train = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    # ReLU function\n",
    "    # Return the maximum of 0 and Z\n",
    "    # In other words:\n",
    "    # If Z is positive, return Z\n",
    "    # If Z is negative, return 0\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def ReLU_deriv(Z):\n",
    "    # Derivative of ReLU function\n",
    "    # Return 1 if Z is positive, 0 otherwise\n",
    "    return Z > 0\n",
    "\n",
    "def softmax(Z):\n",
    "    # Softmax function\n",
    "    # Return the exponential of Z, divided by the sum of the exponential of Z\n",
    "    return np.exp(Z) / sum(np.exp(Z))\n",
    "\n",
    "def one_hot(Y):\n",
    "    # One-hot encoding function\n",
    "    # Return a matrix of 0s with the same shape of Y\n",
    "    # Set the value of the index of Y to 1\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    # Return the transposed matrix to match the shape of the input\n",
    "    return one_hot_Y.T    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    # Initialize the parameters\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    \n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    \n",
    "    W3 = np.random.rand(10, 10) - 0.5\n",
    "    b3 = np.random.rand(10, 1) - 0.5\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "def forward_prop(W1, b1, W2, b2, W3, b3, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    \n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = ReLU(Z2)\n",
    "    \n",
    "    Z3 = W3.dot(A2) + b3\n",
    "    A3 = softmax(Z3)\n",
    "    \n",
    "    return Z1, A1, Z2, A2, Z3, A3\n",
    "    \n",
    "def back_prop(Z1, A1, Z2, A2, Z3, A3, W2, W3, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    \n",
    "    dZ3 = A3 - one_hot_Y\n",
    "    dW3 = 1 / m * dZ3.dot(A2.T)\n",
    "    db3 = 1 / m * np.sum(dZ3)\n",
    "    \n",
    "    dZ2 = W3.T.dot(dZ3) * ReLU_deriv(Z2)\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2)\n",
    "    \n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1)\n",
    "    \n",
    "    return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "def adam(params, grads, v, s, t, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    for param, grad, v_param, s_param in zip(params, grads, v, s):\n",
    "        v_param = beta1 * v_param + (1 - beta1) * grad\n",
    "        s_param = beta2 * s_param + (1 - beta2) * (grad ** 2)\n",
    "        v_corrected = v_param / (1 - beta1 ** t)\n",
    "        s_corrected = s_param / (1 - beta2 ** t)\n",
    "        param -= learning_rate * v_corrected / (np.sqrt(s_corrected) + epsilon)\n",
    "    return params, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A3):\n",
    "    # Get the index of the maximum value in A3\n",
    "    return np.argmax(A3, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    # Calculate the accuracy of the predictions\n",
    "    print(predictions, Y)\n",
    "    # Return the number of correct predictions\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, iters, learning_rate):\n",
    "    W1, b1, W2, b2, W3, b3 = init_params()\n",
    "    v = [np.zeros_like(W1), np.zeros_like(b1), np.zeros_like(W2), np.zeros_like(b2), np.zeros_like(W3), np.zeros_like(b3)]\n",
    "    s = [np.zeros_like(W1), np.zeros_like(b1), np.zeros_like(W2), np.zeros_like(b2), np.zeros_like(W3), np.zeros_like(b3)]\n",
    "    params = [W1, b1, W2, b2, W3, b3]\n",
    "    \n",
    "    for i in range(iters):\n",
    "        Z1, A1, Z2, A2, Z3, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "        dW1, db1, dW2, db2, dW3, db3 = back_prop(Z1, A1, Z2, A2, Z3, A3, W2, W3, X, Y)\n",
    "        grads = [dW1, db1, dW2, db2, dW3, db3]\n",
    "        \n",
    "        params, v, s = adam(params, grads, v, s, i+1, learning_rate)\n",
    "        W1, b1, W2, b2, W3, b3 = params\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Iteration {i}\")\n",
    "            predictions = get_predictions(A3)\n",
    "            print(f\"Accuracy: {get_accuracy(predictions, Y)}\")\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "[1 3 1 ... 3 1 1] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.09046341463414634\n",
      "Iteration 10\n",
      "[1 3 1 ... 3 1 1] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.10163414634146341\n",
      "Iteration 20\n",
      "[1 3 5 ... 1 1 1] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.11448780487804879\n",
      "Iteration 30\n",
      "[1 3 5 ... 1 1 1] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.136\n",
      "Iteration 40\n",
      "[1 3 5 ... 1 1 1] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.16726829268292684\n",
      "Iteration 50\n",
      "[1 3 5 ... 1 1 3] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.2064390243902439\n",
      "Iteration 60\n",
      "[1 3 5 ... 1 1 3] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.25034146341463415\n",
      "Iteration 70\n",
      "[1 5 7 ... 1 1 3] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.30148780487804877\n",
      "Iteration 80\n",
      "[1 5 7 ... 1 1 3] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.3533414634146341\n",
      "Iteration 90\n",
      "[1 8 7 ... 1 1 3] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.4063414634146341\n",
      "Iteration 100\n",
      "[1 8 7 ... 1 1 3] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.46002439024390246\n",
      "Iteration 110\n",
      "[1 8 7 ... 1 1 3] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.5126829268292683\n",
      "Iteration 120\n",
      "[1 8 7 ... 1 1 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.5642439024390243\n",
      "Iteration 130\n",
      "[1 8 7 ... 1 1 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.6110975609756097\n",
      "Iteration 140\n",
      "[0 8 7 ... 1 1 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.6538536585365854\n",
      "Iteration 150\n",
      "[0 8 7 ... 1 1 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.6861463414634147\n",
      "Iteration 160\n",
      "[0 8 7 ... 5 1 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.7127317073170731\n",
      "Iteration 170\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.7356341463414634\n",
      "Iteration 180\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.7540731707317073\n",
      "Iteration 190\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.7685853658536586\n",
      "Iteration 200\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.7823170731707317\n",
      "Iteration 210\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.7935853658536586\n",
      "Iteration 220\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8032682926829269\n",
      "Iteration 230\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8110731707317074\n",
      "Iteration 240\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8184878048780487\n",
      "Iteration 250\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8244146341463414\n",
      "Iteration 260\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8293170731707317\n",
      "Iteration 270\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8334634146341463\n",
      "Iteration 280\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.838170731707317\n",
      "Iteration 290\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8422439024390244\n",
      "Iteration 300\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8455365853658536\n",
      "Iteration 310\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8483414634146341\n",
      "Iteration 320\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8505365853658536\n",
      "Iteration 330\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8526341463414634\n",
      "Iteration 340\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8546585365853658\n",
      "Iteration 350\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8562926829268293\n",
      "Iteration 360\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8578048780487805\n",
      "Iteration 370\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8589024390243902\n",
      "Iteration 380\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8601707317073171\n",
      "Iteration 390\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8612926829268293\n",
      "Iteration 400\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8622682926829268\n",
      "Iteration 410\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8634390243902439\n",
      "Iteration 420\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8645853658536585\n",
      "Iteration 430\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8655609756097561\n",
      "Iteration 440\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8660975609756097\n",
      "Iteration 450\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8666341463414634\n",
      "Iteration 460\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.867\n",
      "Iteration 470\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8676341463414634\n",
      "Iteration 480\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.868219512195122\n",
      "Iteration 490\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8685853658536585\n",
      "Iteration 500\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.868609756097561\n",
      "Iteration 510\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8690243902439024\n",
      "Iteration 520\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8691219512195122\n",
      "Iteration 530\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8697560975609756\n",
      "Iteration 540\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8697073170731707\n",
      "Iteration 550\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.87\n",
      "Iteration 560\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8700975609756098\n",
      "Iteration 570\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8704878048780488\n",
      "Iteration 580\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8708048780487805\n",
      "Iteration 590\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.870780487804878\n",
      "Iteration 600\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8709024390243902\n",
      "Iteration 610\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8711707317073171\n",
      "Iteration 620\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8713658536585366\n",
      "Iteration 630\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8714634146341463\n",
      "Iteration 640\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8716585365853659\n",
      "Iteration 650\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8718292682926829\n",
      "Iteration 660\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8720487804878049\n",
      "Iteration 670\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8722439024390244\n",
      "Iteration 680\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8725121951219512\n",
      "Iteration 690\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8727073170731707\n",
      "Iteration 700\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8729268292682927\n",
      "Iteration 710\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8729024390243902\n",
      "Iteration 720\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8731219512195122\n",
      "Iteration 730\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8731951219512195\n",
      "Iteration 740\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.873219512195122\n",
      "Iteration 750\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8733170731707317\n",
      "Iteration 760\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8734634146341463\n",
      "Iteration 770\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8735853658536585\n",
      "Iteration 780\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.873609756097561\n",
      "Iteration 790\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8736341463414634\n",
      "Iteration 800\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8737073170731707\n",
      "Iteration 810\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8737317073170732\n",
      "Iteration 820\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8738780487804878\n",
      "Iteration 830\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8738292682926829\n",
      "Iteration 840\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8738536585365854\n",
      "Iteration 850\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8739756097560976\n",
      "Iteration 860\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.874219512195122\n",
      "Iteration 870\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8742682926829268\n",
      "Iteration 880\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.874390243902439\n",
      "Iteration 890\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8743414634146341\n",
      "Iteration 900\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8743170731707317\n",
      "Iteration 910\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8743414634146341\n",
      "Iteration 920\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8744878048780488\n",
      "Iteration 930\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8745121951219512\n",
      "Iteration 940\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8747073170731707\n",
      "Iteration 950\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8746829268292683\n",
      "Iteration 960\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8746829268292683\n",
      "Iteration 970\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8747560975609756\n",
      "Iteration 980\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8747560975609756\n",
      "Iteration 990\n",
      "[0 8 7 ... 5 2 6] [0 8 7 ... 5 2 6]\n",
      "Accuracy: 0.8747073170731707\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2, W3, b3 = gradient_descent(X_train, Y_train, 1000, 0.001)  # Note: typically use a lower learning rate with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2, W3, b3):\n",
    "    _, _, _, _, _, A3 = forward_prop(W1, b1, W2, b2, W3, b3, X)\n",
    "    predictions = get_predictions(A3)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2, W3, b3):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2, W3, b3)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [0]\n",
      "Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(679, W1, b1, W2, b2, W3, b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 7 6 7 3 8 3 2 1 2 5 8 7 8 6 2 3 5 8 9 8 4 7 6 3 1 7 6 2 7 1 2 8 4 0 9 9\n",
      " 7 9 2 1 4 8 1 9 2 2 5 1 8 2 1 5 4 1 8 7 3 1 4 6 4 4 0 1 5 3 9 2 2 9 0 1 5\n",
      " 8 7 9 7 6 8 9 5 8 1 7 1 8 0 4 6 1 3 1 5 7 3 5 5 1 1 6 0 1 8 3 8 5 8 3 6 8\n",
      " 5 9 0 7 2 7 5 8 3 3 2 0 8 1 1 1 0 3 1 2 7 8 8 1 5 0 9 3 2 8 8 9 3 7 7 8 2\n",
      " 7 6 3 0 1 4 2 4 5 0 0 9 7 9 1 7 2 6 1 8 7 2 8 5 6 6 1 0 2 3 6 1 3 5 6 9 9\n",
      " 1 4 9 0 1 5 5 7 0 5 7 7 1 1 5 0 2 6 6 7 4 1 5 6 5 0 8 4 7 1 5 6 6 5 3 9 3\n",
      " 9 9 8 6 8 0 0 1 5 1 1 2 5 3 1 6 2 4 5 8 2 6 1 2 0 9 7 4 1 5 8 7 6 4 0 0 7\n",
      " 0 5 8 1 3 9 4 5 6 6 0 4 7 7 3 2 0 1 8 8 9 6 1 2 6 7 3 3 1 6 3 9 8 9 6 4 5\n",
      " 2 2 6 1 9 2 3 6 2 4 1 5 9 0 0 6 3 1 7 2 7 6 4 4 5 4 5 4 7 5 5 1 6 6 5 5 1\n",
      " 6 8 2 4 6 5 8 9 8 6 1 0 4 1 1 2 4 1 5 7 2 9 1 8 3 8 6 2 2 1 4 5 2 5 7 1 9\n",
      " 4 9 0 4 6 8 6 6 5 1 7 6 2 5 5 5 1 5 3 4 1 1 4 6 1 7 6 1 3 5 3 6 2 7 2 5 2\n",
      " 5 7 7 3 0 9 5 0 2 3 3 1 8 3 2 1 3 8 9 0 0 7 3 4 4 8 8 4 1 1 9 3 0 8 1 4 4\n",
      " 3 2 6 3 7 9 7 3 1 0 5 3 5 1 4 9 3 7 8 1 7 5 7 1 8 7 7 5 0 7 5 5 9 6 2 3 7\n",
      " 8 6 6 8 1 4 5 3 1 3 5 2 7 8 7 4 2 6 2 1 6 9 7 7 1 4 5 9 2 9 7 4 6 7 6 8 6\n",
      " 3 3 8 3 0 2 8 0 1 6 3 6 2 2 5 2 6 1 5 0 8 6 3 7 5 2 6 4 0 8 5 2 1 1 8 9 4\n",
      " 2 4 1 4 5 0 9 2 0 8 5 8 7 1 7 8 1 1 3 0 4 3 5 2 4 7 1 8 0 8 7 0 6 1 2 9 2\n",
      " 0 0 9 5 0 6 6 7 3 5 2 6 3 9 2 9 4 7 9 9 8 1 6 4 1 4 6 1 0 6 5 0 2 2 2 6 7\n",
      " 5 2 8 5 0 1 7 6 2 3 0 4 5 4 0 6 7 8 0 2 1 1 0 5 9 3 9 9 1 1 3 3 4 4 0 0 9\n",
      " 7 6 6 7 0 9 8 8 4 1 0 2 2 5 6 6 7 7 4 3 2 9 2 1 0 2 6 4 4 2 9 2 0 1 7 0 9\n",
      " 9 4 2 4 4 7 9 7 7 4 0 7 3 5 1 0 0 3 7 6 1 6 5 2 1 5 6 1 6 9 2 2 6 1 1 0 4\n",
      " 5 6 2 6 1 4 0 0 3 5 6 5 1 9 1 3 3 7 4 7 2 2 8 6 2 5 2 3 8 0 8 2 6 9 7 2 6\n",
      " 6 7 7 0 1 9 0 0 7 0 1 0 0 7 1 3 8 2 9 8 4 4 4 5 2 7 9 8 8 0 1 3 6 6 7 1 8\n",
      " 7 2 7 7 9 7 4 6 2 3 6 3 2 2 1 6 9 9 4 9 0 4 4 0 6 5 2 5 1 0 8 6 6 5 0 9 4\n",
      " 5 6 1 6 6 6 6 3 5 4 7 3 9 7 8 3 8 8 1 5 6 7 8 1 3 3 4 1 7 8 1 0 7 0 9 3 7\n",
      " 3 0 3 4 9 7 0 0 7 4 0 0 1 7 7 8 8 6 7 1 1 3 1 8 1 8 5 5 4 2 7 6 3 8 9 7 0\n",
      " 3 3 3 3 0 9 0 8 0 8 5 7 0 5 0 9 0 6 8 6 3 6 7 0 5 8 9 6 7 4 0 6 5 8 4 8 3\n",
      " 7 8 3 1 0 6 0 8 0 0 0 5 2 8 8 2 8 5 6 7 3 3 2 4 7 8 7 9 8 5 0 7 5 3 3 0 5\n",
      " 3] [3 9 6 7 3 8 3 2 1 2 5 8 7 8 6 2 3 5 8 7 8 4 7 6 3 1 7 6 2 7 1 2 8 4 0 9 9\n",
      " 7 9 2 2 4 8 1 9 2 2 5 3 8 2 1 5 4 1 0 3 3 1 4 6 4 5 0 1 5 3 9 2 2 9 0 1 5\n",
      " 8 7 9 7 6 8 7 5 5 1 7 1 8 0 4 6 1 3 1 5 7 3 5 0 1 1 0 0 1 8 3 1 5 2 3 6 8\n",
      " 5 9 0 7 3 9 5 8 3 3 2 0 8 1 4 1 0 3 1 2 7 8 8 1 8 0 4 8 2 8 8 7 3 9 9 8 2\n",
      " 7 6 3 0 1 4 2 0 8 0 0 9 7 9 1 7 2 6 1 8 7 7 8 5 6 6 1 0 2 3 6 1 3 0 6 9 9\n",
      " 1 4 9 0 1 5 5 7 0 5 7 7 1 1 5 0 2 6 6 7 4 1 5 6 5 0 2 4 7 1 5 6 6 5 3 9 3\n",
      " 7 9 8 6 8 0 0 1 5 1 1 2 5 5 1 6 2 4 5 8 2 6 1 2 0 9 7 4 1 5 8 7 6 7 0 0 7\n",
      " 0 5 8 1 3 9 4 5 6 6 0 4 7 7 2 2 0 1 8 8 9 6 1 2 6 7 3 3 1 6 3 9 8 9 6 4 8\n",
      " 2 2 6 8 3 2 3 6 2 4 1 5 9 0 0 6 3 1 7 2 7 6 4 4 0 4 5 4 7 5 5 1 6 6 5 5 1\n",
      " 2 8 2 4 6 5 8 9 8 6 8 0 4 1 1 2 4 1 5 7 2 7 1 8 3 8 6 2 2 1 4 0 2 5 7 1 9\n",
      " 4 3 0 9 6 8 6 6 5 1 7 6 2 5 5 5 1 5 3 4 1 1 4 6 1 7 6 1 3 5 3 6 2 7 0 5 2\n",
      " 5 7 7 3 0 9 8 0 2 3 3 1 8 3 2 1 3 2 9 0 0 7 3 4 4 8 8 4 1 1 4 5 0 8 1 4 4\n",
      " 3 2 6 2 7 9 9 3 1 0 5 3 5 1 4 9 3 7 3 1 7 5 7 1 8 7 7 5 0 7 5 3 9 6 2 3 7\n",
      " 8 6 6 3 1 4 5 3 1 3 8 2 7 8 7 2 2 6 2 1 6 9 7 9 1 4 5 7 2 9 7 4 6 7 6 8 6\n",
      " 2 3 8 3 6 2 8 0 1 6 3 6 2 2 5 2 6 1 5 0 2 6 3 7 5 2 0 4 0 8 5 2 1 1 2 9 4\n",
      " 7 4 1 4 5 0 9 2 0 0 5 8 7 1 7 8 1 1 3 8 4 3 5 2 4 7 1 5 0 8 7 0 6 1 2 9 2\n",
      " 0 0 9 5 0 6 6 7 5 5 2 6 3 9 2 9 4 7 9 9 8 1 6 9 1 4 7 1 0 5 8 0 2 2 2 6 7\n",
      " 5 2 8 5 0 1 7 6 2 2 0 4 8 4 0 6 7 8 0 2 1 1 8 5 9 3 9 9 1 7 3 3 4 4 0 2 9\n",
      " 7 4 6 7 0 9 8 8 4 1 0 2 2 5 6 6 9 7 4 3 2 9 2 1 0 2 6 4 4 2 7 2 0 1 7 0 9\n",
      " 9 9 2 4 4 7 9 7 7 4 0 7 3 5 1 0 0 2 7 6 1 6 5 2 1 5 6 5 6 9 2 2 6 1 1 0 4\n",
      " 0 6 2 6 1 4 0 0 3 3 6 5 1 9 1 3 3 7 4 7 2 7 8 4 2 5 2 2 8 0 8 2 6 7 7 2 6\n",
      " 6 7 7 0 1 9 0 0 7 0 1 0 0 7 1 3 8 2 9 8 4 4 4 5 2 9 9 8 8 0 1 2 6 6 7 1 8\n",
      " 7 2 7 7 9 7 4 0 7 3 6 3 2 2 5 6 5 7 4 9 0 4 8 0 6 5 2 5 1 0 8 6 6 5 0 9 4\n",
      " 5 6 1 6 2 6 6 3 5 4 7 9 9 7 8 8 8 8 1 5 6 7 8 1 3 3 5 1 7 5 1 0 7 0 9 8 7\n",
      " 3 0 3 4 9 7 0 6 7 9 0 0 1 7 7 8 8 6 7 1 1 3 1 8 1 8 5 5 4 2 7 6 3 0 9 9 0\n",
      " 9 3 8 3 0 9 0 8 0 8 5 7 0 5 5 9 0 6 8 6 2 0 9 0 5 8 9 6 7 2 0 6 5 8 4 8 3\n",
      " 7 8 3 1 0 6 0 8 0 0 0 5 2 2 8 2 8 8 6 7 3 3 2 4 7 8 7 9 8 5 0 7 5 3 3 0 0\n",
      " 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2, W3, b3)\n",
    "get_accuracy(dev_predictions, Y_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
